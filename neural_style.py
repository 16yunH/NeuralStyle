"""
é«˜çº§ç¥ç»é£æ ¼è¿ç§»å®ç°
æ”¯æŒå¤šç§ä¼˜åŒ–é€‰é¡¹å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import os
import warnings
from datetime import datetime

import matplotlib.pyplot as plt
import torch
import torch.optim as optim

warnings.filterwarnings('ignore')

from config import get_config
from models import VGGFeatures, ContentLoss, StyleLoss, TotalVariationLoss, preserve_color
from utils import (load_image, im_convert, save_image, create_gif, plot_progress,
                   get_timestamp, print_progress, validate_paths)

class NeuralStyleTransfer:
    """ç¥ç»é£æ ¼è¿ç§»ç±»"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f'ä½¿ç”¨è®¾å¤‡: {self.device}')
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.vgg_features = VGGFeatures(self.device)
        
        # æŸå¤±è®°å½•
        self.losses = {'total': [], 'content': [], 'style': [], 'tv': []}
        
        # ä¸­é—´ç»“æœ
        self.intermediate_images = []
        
    def load_images(self):
        """åŠ è½½å†…å®¹å’Œé£æ ¼å›¾åƒ"""
        print("éªŒè¯å›¾åƒè·¯å¾„...")
        validate_paths(self.config.content_path, self.config.style_path)
        
        print(f"åŠ è½½å†…å®¹å›¾åƒ: {self.config.content_path}")
        self.content_img = load_image(
            self.config.content_path, 
            self.config.max_size, 
            device=self.device
        )
        
        print(f"åŠ è½½é£æ ¼å›¾åƒ: {self.config.style_path}")
        self.style_img = load_image(
            self.config.style_path, 
            shape=self.content_img.shape[-2:], 
            device=self.device
        )
        
        # åˆå§‹åŒ–ç›®æ ‡å›¾åƒ
        self.target_img = self.content_img.clone().requires_grad_(True).to(self.device)
        
        print(f"å›¾åƒå°ºå¯¸: {self.content_img.shape[-2:]}")
        
    def setup_losses(self):
        """è®¾ç½®æŸå¤±å‡½æ•°"""
        print("è®¾ç½®æŸå¤±å‡½æ•°...")
        
        # æå–å†…å®¹å’Œé£æ ¼ç‰¹å¾
        content_features = self.vgg_features(self.content_img)
        style_features = self.vgg_features(self.style_img)
        
        # å†…å®¹æŸå¤±
        self.content_loss = ContentLoss(content_features[self.config.content_layer])
        
        # é£æ ¼æŸå¤±
        self.style_losses = {}
        for layer, weight in self.config.style_layers.items():
            if layer in style_features:
                self.style_losses[layer] = {
                    'loss': StyleLoss(style_features[layer]),
                    'weight': weight
                }
        
        # æ€»å˜åˆ†æŸå¤±
        if self.config.total_variation_weight > 0:
            self.tv_loss = TotalVariationLoss(self.config.total_variation_weight)
        else:
            self.tv_loss = None
            
        print(f"å†…å®¹å±‚: {self.config.content_layer}")
        print(f"é£æ ¼å±‚: {list(self.style_losses.keys())}")
        
    def optimize(self):
        """æ‰§è¡Œä¼˜åŒ–è¿‡ç¨‹"""
        print("å¼€å§‹é£æ ¼è¿ç§»...")
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        optimizer = optim.Adam([self.target_img], lr=self.config.learning_rate)
        
        start_time = datetime.now()
        
        for iteration in range(1, self.config.iterations + 1):
            # æ¸…é›¶æ¢¯åº¦
            optimizer.zero_grad()
            
            # æå–ç›®æ ‡å›¾åƒç‰¹å¾
            target_features = self.vgg_features(self.target_img)
            
            # è®¡ç®—å†…å®¹æŸå¤±
            content_loss = self.content_loss(target_features[self.config.content_layer])
            content_loss *= self.config.content_weight
            
            # è®¡ç®—é£æ ¼æŸå¤±
            style_loss = 0
            for layer, loss_info in self.style_losses.items():
                if layer in target_features:
                    layer_loss = loss_info['loss'](target_features[layer])
                    style_loss += layer_loss * loss_info['weight']
            style_loss *= self.config.style_weight
            
            # è®¡ç®—æ€»å˜åˆ†æŸå¤±
            tv_loss = 0
            if self.tv_loss:
                tv_loss = self.tv_loss(self.target_img)
            
            # æ€»æŸå¤±
            total_loss = content_loss + style_loss + tv_loss
            
            # åå‘ä¼ æ’­
            total_loss.backward()
            optimizer.step()
            
            # è®°å½•æŸå¤±
            self.losses['total'].append(total_loss.item())
            self.losses['content'].append(content_loss.item())
            self.losses['style'].append(style_loss.item())
            self.losses['tv'].append(tv_loss.item() if isinstance(tv_loss, torch.Tensor) else 0)
            
            # æ˜¾ç¤ºè¿›åº¦
            if iteration % self.config.show_every == 0:
                print_progress(iteration, self.config.iterations, self.losses, start_time)
                
                # å¯è§†åŒ–å½“å‰ç»“æœ
                self.visualize_current_result()
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if self.config.save_intermediate and iteration % self.config.save_every == 0:
                self.save_intermediate_result(iteration)
                self.intermediate_images.append(self.target_img.clone())
        
        print(f"\nä¼˜åŒ–å®Œæˆï¼æ€»ç”¨æ—¶: {datetime.now() - start_time}")
        
    def visualize_current_result(self):
        """å¯è§†åŒ–å½“å‰ç»“æœ"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # å†…å®¹å›¾åƒ
        axes[0].imshow(im_convert(self.content_img))
        axes[0].set_title('Content Image')
        axes[0].axis('off')
        
        # é£æ ¼å›¾åƒ
        axes[1].imshow(im_convert(self.style_img))
        axes[1].set_title('Style Image')
        axes[1].axis('off')
        
        # å½“å‰ç»“æœ
        current_result = self.target_img.clone()
        if self.config.preserve_colors:
            current_result = preserve_color(self.content_img, current_result)
            
        axes[2].imshow(im_convert(current_result))
        axes[2].set_title('Current Result')
        axes[2].axis('off')
        
        plt.tight_layout()
        plt.show()
        
    def save_intermediate_result(self, iteration):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        output_dir = os.path.join(self.config.output_dir, 'intermediate')
        os.makedirs(output_dir, exist_ok=True)
        
        filename = f'iter_{iteration:04d}.jpg'
        filepath = os.path.join(output_dir, filename)
        
        current_result = self.target_img.clone()
        if self.config.preserve_colors:
            current_result = preserve_color(self.content_img, current_result)
            
        save_image(current_result, filepath)
        
    def save_final_result(self):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        print("ä¿å­˜æœ€ç»ˆç»“æœ...")
        
        os.makedirs(self.config.output_dir, exist_ok=True)
        
        # æœ€ç»ˆç»“æœ
        final_result = self.target_img.clone()
        if self.config.preserve_colors:
            final_result = preserve_color(self.content_img, final_result)
        
        # ä¿å­˜ä¸»è¦ç»“æœ
        timestamp = get_timestamp()
        main_output = os.path.join(self.config.output_dir, f'styled_{timestamp}.jpg')
        save_image(final_result, main_output, "æœ€ç»ˆç»“æœå·²ä¿å­˜")
        
        # ä¿å­˜å¯¹æ¯”å›¾
        self.save_comparison(final_result, timestamp)
        
        # ä¿å­˜æŸå¤±æ›²çº¿
        loss_plot_path = os.path.join(self.config.output_dir, f'losses_{timestamp}.png')
        plot_progress(self.losses, loss_plot_path)
        
        # åˆ›å»ºGIFï¼ˆå¦‚æœæœ‰ä¸­é—´ç»“æœï¼‰
        if self.intermediate_images:
            gif_path = os.path.join(self.config.output_dir, f'process_{timestamp}.gif')
            create_gif(self.intermediate_images, gif_path)
            print(f"å¤„ç†è¿‡ç¨‹GIFå·²ä¿å­˜: {gif_path}")
            
    def save_comparison(self, final_result, timestamp):
        """ä¿å­˜å¯¹æ¯”å›¾"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        axes[0].imshow(im_convert(self.content_img))
        axes[0].set_title('Content Image')
        axes[0].axis('off')
        
        axes[1].imshow(im_convert(self.style_img))
        axes[1].set_title('Style Image')
        axes[1].axis('off')
        
        axes[2].imshow(im_convert(final_result))
        axes[2].set_title('Result')
        axes[2].axis('off')
        
        plt.tight_layout()
        comparison_path = os.path.join(self.config.output_dir, f'comparison_{timestamp}.png')
        plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"å¯¹æ¯”å›¾å·²ä¿å­˜: {comparison_path}")
        
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„é£æ ¼è¿ç§»æµç¨‹"""
        try:
            self.load_images()
            self.setup_losses()
            self.optimize()
            self.save_final_result()
            
            print("\nğŸ¨ ç¥ç»é£æ ¼è¿ç§»å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    # è·å–é…ç½®
    config = get_config()
    
    # åˆ›å»ºå¹¶è¿è¡Œé£æ ¼è¿ç§»
    nst = NeuralStyleTransfer(config)
    nst.run()

if __name__ == "__main__":
    main()
