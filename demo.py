"""
æ¼”ç¤ºè„šæœ¬ - å±•ç¤ºä¸åŒçš„é£æ ¼è¿ç§»æ•ˆæœ
"""

import os

import matplotlib.pyplot as plt
import torch

from config import Config
from neural_style import NeuralStyleTransfer
from utils import im_convert


def demo_basic_style_transfer():
    """åŸºç¡€é£æ ¼è¿ç§»æ¼”ç¤º"""
    print("ğŸ¨ åŸºç¡€é£æ ¼è¿ç§»æ¼”ç¤º")
    
    config = Config()
    config.iterations = 1000
    config.max_size = 512
    config.show_every = 200
    
    nst = NeuralStyleTransfer(config)
    nst.run()

def demo_parameter_comparison():
    """å‚æ•°å¯¹æ¯”æ¼”ç¤º"""
    print("ğŸ“Š å‚æ•°å¯¹æ¯”æ¼”ç¤º")
    
    # ä¸åŒçš„é£æ ¼æƒé‡
    style_weights = [1e4, 1e6, 1e8]
    results = []
    
    for weight in style_weights:
        print(f"æµ‹è¯•é£æ ¼æƒé‡: {weight}")
        
        config = Config()
        config.style_weight = weight
        config.iterations = 500  # å¿«é€Ÿæµ‹è¯•
        config.max_size = 256
        config.show_every = 1000  # ä¸æ˜¾ç¤ºä¸­é—´è¿‡ç¨‹
        
        nst = NeuralStyleTransfer(config)
        nst.load_images()
        nst.setup_losses()
        nst.optimize()
        
        results.append(nst.target_img.clone())
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    fig, axes = plt.subplots(1, len(style_weights) + 2, figsize=(20, 4))
    
    # å†…å®¹å›¾åƒ
    axes[0].imshow(im_convert(nst.content_img))
    axes[0].set_title('Content')
    axes[0].axis('off')
    
    # é£æ ¼å›¾åƒ
    axes[1].imshow(im_convert(nst.style_img))
    axes[1].set_title('Style')
    axes[1].axis('off')
    
    # ä¸åŒæƒé‡çš„ç»“æœ
    for i, (result, weight) in enumerate(zip(results, style_weights)):
        axes[i + 2].imshow(im_convert(result))
        axes[i + 2].set_title(f'Style Weight: {weight:.0e}')
        axes[i + 2].axis('off')
    
    plt.tight_layout()
    plt.savefig('output/parameter_comparison.png', dpi=150, bbox_inches='tight')
    plt.show()

def demo_color_preservation():
    """é¢œè‰²ä¿æŒæ¼”ç¤º"""
    print("ğŸŒˆ é¢œè‰²ä¿æŒæ¼”ç¤º")
    
    from models import preserve_color
    
    config = Config()
    config.iterations = 1000
    config.max_size = 512
    config.show_every = 1000
    
    # ä¸ä¿æŒé¢œè‰²çš„ç»“æœ
    nst1 = NeuralStyleTransfer(config)
    nst1.load_images()
    nst1.setup_losses()
    nst1.optimize()
    result_normal = nst1.target_img.clone()
    
    # ä¿æŒé¢œè‰²çš„ç»“æœ
    result_preserved = preserve_color(nst1.content_img, result_normal)
    
    # æ˜¾ç¤ºå¯¹æ¯”
    fig, axes = plt.subplots(1, 4, figsize=(16, 4))
    
    axes[0].imshow(im_convert(nst1.content_img))
    axes[0].set_title('Content')
    axes[0].axis('off')
    
    axes[1].imshow(im_convert(nst1.style_img))
    axes[1].set_title('Style')
    axes[1].axis('off')
    
    axes[2].imshow(im_convert(result_normal))
    axes[2].set_title('Normal Transfer')
    axes[2].axis('off')
    
    axes[3].imshow(im_convert(result_preserved))
    axes[3].set_title('Color Preserved')
    axes[3].axis('off')
    
    plt.tight_layout()
    plt.savefig('output/color_preservation_demo.png', dpi=150, bbox_inches='tight')
    plt.show()

def demo_multi_style():
    """å¤šé£æ ¼æ··åˆæ¼”ç¤º"""
    print("ğŸ­ å¤šé£æ ¼æ··åˆæ¼”ç¤º")
    
    # æ³¨æ„ï¼šè¿™éœ€è¦å¤šä¸ªé£æ ¼å›¾åƒ
    style_paths = [
        'data/style/style.jpg',
        # å¯ä»¥æ·»åŠ æ›´å¤šé£æ ¼å›¾åƒ
    ]
    
    if len(style_paths) < 2:
        print("âš ï¸  éœ€è¦è‡³å°‘2ä¸ªé£æ ¼å›¾åƒè¿›è¡Œå¤šé£æ ¼æ¼”ç¤º")
        return
    
    # å®ç°å¤šé£æ ¼æ··åˆé€»è¾‘
    # è¿™é‡Œå¯ä»¥æ‰©å±•å®ç°å¤šé£æ ¼çš„æ··åˆæ•ˆæœ
    print("å¤šé£æ ¼æ··åˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

def demo_progressive_transfer():
    """æ¸è¿›å¼é£æ ¼è¿ç§»æ¼”ç¤º"""
    print("â³ æ¸è¿›å¼é£æ ¼è¿ç§»æ¼”ç¤º")
    
    config = Config()
    config.iterations = 2000
    config.max_size = 512
    config.show_every = 200
    config.save_intermediate = True
    config.save_every = 200
    
    nst = NeuralStyleTransfer(config)
    nst.load_images()
    nst.setup_losses()
    
    # è®°å½•å…³é”®é˜¶æ®µ
    key_iterations = [200, 500, 1000, 1500, 2000]
    results = []
    
    optimizer = torch.optim.Adam([nst.target_img], lr=config.learning_rate)
    
    for iteration in range(1, config.iterations + 1):
        # æ ‡å‡†ä¼˜åŒ–æ­¥éª¤
        optimizer.zero_grad()
        
        target_features = nst.vgg_features(nst.target_img)
        
        content_loss = nst.content_loss(target_features[config.content_layer])
        content_loss *= config.content_weight
        
        style_loss = 0
        for layer, loss_info in nst.style_losses.items():
            if layer in target_features:
                layer_loss = loss_info['loss'](target_features[layer])
                style_loss += layer_loss * loss_info['weight']
        style_loss *= config.style_weight
        
        total_loss = content_loss + style_loss
        total_loss.backward()
        optimizer.step()
        
        # ä¿å­˜å…³é”®é˜¶æ®µ
        if iteration in key_iterations:
            results.append(nst.target_img.clone())
            print(f"ä¿å­˜ç¬¬ {iteration} æ¬¡è¿­ä»£ç»“æœ")
    
    # æ˜¾ç¤ºæ¸è¿›è¿‡ç¨‹
    fig, axes = plt.subplots(1, len(key_iterations) + 2, figsize=(4 * (len(key_iterations) + 2), 4))
    
    axes[0].imshow(im_convert(nst.content_img))
    axes[0].set_title('Content')
    axes[0].axis('off')
    
    axes[1].imshow(im_convert(nst.style_img))
    axes[1].set_title('Style')
    axes[1].axis('off')
    
    for i, (result, iteration) in enumerate(zip(results, key_iterations)):
        axes[i + 2].imshow(im_convert(result))
        axes[i + 2].set_title(f'Iter {iteration}')
        axes[i + 2].axis('off')
    
    plt.tight_layout()
    plt.savefig('output/progressive_transfer.png', dpi=150, bbox_inches='tight')
    plt.show()

def run_all_demos():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰æ¼”ç¤º...")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs('output', exist_ok=True)
    
    try:
        demo_basic_style_transfer()
        demo_parameter_comparison()
        demo_color_preservation()
        demo_progressive_transfer()
        
        print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¥ç»é£æ ¼è¿ç§»æ¼”ç¤º')
    parser.add_argument('--demo', choices=['basic', 'params', 'color', 'progressive', 'all'], 
                        default='all', help='é€‰æ‹©æ¼”ç¤ºç±»å‹')
    
    args = parser.parse_args()
    
    if args.demo == 'basic':
        demo_basic_style_transfer()
    elif args.demo == 'params':
        demo_parameter_comparison()
    elif args.demo == 'color':
        demo_color_preservation()
    elif args.demo == 'progressive':
        demo_progressive_transfer()
    elif args.demo == 'all':
        run_all_demos()
